{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFikRxUPPVpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "dd00aa36-5be5-49f5-fd61-77ed01033062",
        "tags": []
      },
      "source": [
        "!pip install SpeechRecognition pydub ffmpy converter ffmpeg-python audioread google-cloud-speech --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvYfocKKqlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "import shutil\n",
        "import ffmpy\n",
        "import subprocess\n",
        "import glob\n",
        "  \n",
        "from pydub import AudioSegment \n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.playback import play"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "folder = \"discursos\"\n",
        "os.chdir(folder) \n",
        "\n",
        "files = glob.glob(\"*.mp4\")\n",
        "for filename in files:\n",
        "    filenameMp3 = filename[:-4]\n",
        "    print(\"Traspasando mp4 a wav el archivo: \" + filename)\n",
        "    os.system('ffmpeg -i {} -vn -acodec pcm_s16le -ar 44100 -ac 2 {}.wav'.format(filename, filenameMp3))\n",
        "\n",
        "    print(\"moviendo \"+ filename +\" a archivos pasados a wav\")\n",
        "    origen = filename\n",
        "    destino = \"Mp4Transformados/\"+filename\n",
        "    shutil.move(origen, destino)\n",
        "\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "inicia\neru-wodh-sxv (2020-07-09 at 05_48 GMT-7).wav\ndiscursos/eru-wodh-sxv (2020-07-09 at 05_48 GMT-7).wav\ncargando wav\n['discursos', '.gitignore', 'SpeechToTextLocal.ipynb', 'creaCarpetas.sh', 'audio2texto.py', 'trnasformarAmano.txt', 'README.md', '.git', 'SpeechToTextLocalColab.ipynb']\nsplit del audio por silencios\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "---------------------------------------------------------------------------",
            "KeyboardInterrupt                         Traceback (most recent call last)",
            "<ipython-input-4-0725e632fb0e> in <module>()\n      8     print(file)\n      9 \n---> 10     silence_based_conversion(\"discursos/\",file)\n     11     audio2text(file)\n     12 \n",
            "<ipython-input-2-84936679793c> in silence_based_conversion(path, archivo)\n     21         # adjust this per requirement \n     22         silence_thresh = song.dBFS-16,\n---> 23         keep_silence=500\n     24     ) \n     25   \n",
            "/home/amaru/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pydub/silence.py in split_on_silence(audio_segment, min_silence_len, silence_thresh, keep_silence, seek_step)\n    123         [ start - keep_silence, end + keep_silence ]\n    124         for (start,end)\n--> 125             in detect_nonsilent(audio_segment, min_silence_len, silence_thresh, seek_step)\n    126     ]\n    127 \n",
            "/home/amaru/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pydub/silence.py in detect_nonsilent(audio_segment, min_silence_len, silence_thresh, seek_step)\n     63 \n     64 def detect_nonsilent(audio_segment, min_silence_len=1000, silence_thresh=-16, seek_step=1):\n---> 65     silent_ranges = detect_silence(audio_segment, min_silence_len, silence_thresh, seek_step)\n     66     len_seg = len(audio_segment)\n     67 \n",
            "/home/amaru/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pydub/silence.py in detect_silence(audio_segment, min_silence_len, silence_thresh, seek_step)\n     29     for i in slice_starts:\n     30         audio_slice = audio_segment[i:i + min_silence_len]\n---> 31         if audio_slice.rms <= silence_thresh:\n     32             silence_starts.append(i)\n     33 \n",
            "/home/amaru/.pyenv/versions/3.6.9/lib/python3.6/site-packages/pydub/audio_segment.py in rms(self)\n   1025     @property\n   1026     def rms(self):\n-> 1027         return audioop.rms(self._data, self.sample_width)\n   1028 \n   1029     @property\n",
            "KeyboardInterrupt: "
          ]
        }
      ],
      "source": [
        "os.chdir('discursos')\n",
        "files = glob.glob(\"*.wav\")\n",
        "os.chdir('..')\n",
        "\n",
        "r = sr.Recognizer()\n",
        "print(\"inicia\")\n",
        "for file in files:\n",
        "    print(\"Inicia archivo: \"+file)\n",
        "\n",
        "    silence_based_conversion(\"discursos/\",file)\n",
        "    audio2text(file)\n",
        "\n",
        "    print(\"moviendo archivo\")\n",
        "    origen = \"discursos/\"+file\n",
        "    destino = \"discursos/WavListos/\"+file\n",
        "    shutil.move(origen, destino)\n",
        "\n",
        "    shutil.rmtree('audio_chunks')\n",
        "print(\"termina\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMFQwy8iTEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def silence_based_conversion(path,archivo): \n",
        "  \n",
        "    # open the audio file stored in \n",
        "    # the local system as a wav file.\n",
        "    print(path+archivo)\n",
        "    print(\"cargando wav\")\n",
        "    print(os.listdir())\n",
        "    song = AudioSegment.from_wav(path+archivo)\n",
        "    #play(song)\n",
        "          \n",
        "    # split track where silence is 0.5 seconds  \n",
        "    # or more and get chunks \n",
        "    print(\"split del audio por silencios\")\n",
        "    chunks = split_on_silence(song, \n",
        "        # must be silent for at least 0.5 seconds \n",
        "        # or 500 ms. adjust this value based on user \n",
        "        # requirement. if the speaker stays silent for  \n",
        "        # longer, increase this value. else, decrease it. \n",
        "        min_silence_len = 500, \n",
        "        # consider it silent if quieter than -16 dBFS \n",
        "        # adjust this per requirement \n",
        "        silence_thresh = song.dBFS-16,\n",
        "        keep_silence=500\n",
        "    ) \n",
        "  \n",
        "    # create a directory to store the audio chunks. \n",
        "    try: \n",
        "        print(\"creacion del fichero audio_chunks\")\n",
        "        os.mkdir('audio_chunks') \n",
        "    except(FileExistsError): \n",
        "        pass\n",
        "  \n",
        "    # move into the directory to \n",
        "    # store the audio files. \n",
        "    print(\"entra al fichero audio_chunks\")\n",
        "    os.chdir('audio_chunks') \n",
        "  \n",
        "    i = 0\n",
        "    # process each chunk \n",
        "    print(\"se inicia el prceso de los audios\")\n",
        "    for chunk in chunks: \n",
        "              \n",
        "        # Create 0.5 seconds silence chunk \n",
        "        chunk_silent = AudioSegment.silent(duration = 100) \n",
        "  \n",
        "        # add 0.5 sec silence to beginning and  \n",
        "        # end of audio chunk. This is done so that \n",
        "        # it doesn't seem abruptly sliced. \n",
        "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
        "  \n",
        "        # export audio chunk and save it in  \n",
        "        # the current directory. \n",
        "        print(\"saving chunk{0}.wav\".format(i)) \n",
        "        # specify the bitrate to be 192 k \n",
        "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
        "  \n",
        "        # the name of the newly created chunk \n",
        "        filename = 'chunk'+str(i)+'.wav'\n",
        "        print(\"Processing chunk \"+str(i)+\" - filename: \"+filename) \n",
        "        \n",
        "        i += 1\n",
        "  \n",
        "        \n",
        "\n",
        "    print(\"paso atras en la carpeta\")\n",
        "    os.chdir('..') \n",
        "  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def audio2text(archivo = \"recognized\"):\n",
        "    \n",
        "    os.chdir(\"audio_chunks\")\n",
        "\n",
        "    # open a file where we will concatenate   \n",
        "    # and store the recognized text \n",
        "    print(\"creando archivo recognized.txt\")\n",
        "    fh = open(\"../discursos/\"+archivo[:-4]+\".txt\", \"w+\") \n",
        "\n",
        "    audios = os.listdir()\n",
        "\n",
        "    i = 0\n",
        "    for audio in audios:\n",
        "        # get the name of the newly created chunk \n",
        "        # in the AUDIO_FILE variable for later use.\n",
        "        file = \"chunk{0}.wav\".format(i)\n",
        "        i += 1\n",
        "        print(file)\n",
        "\n",
        "        # create a speech recognition object \n",
        "        r = sr.Recognizer()\n",
        "\n",
        "        # recognize the chunk \n",
        "        with sr.AudioFile(file) as source: \n",
        "\n",
        "            #song = AudioSegment.from_wav(audio)\n",
        "            #play(song)\n",
        "\n",
        "            # remove this if it is not working \n",
        "            # correctly. \n",
        "            print(\"cargando Archivo\")\n",
        "            #r.adjust_for_ambient_noise(source) \n",
        "            audio_listened = r.listen(source)\n",
        "\n",
        "        try: \n",
        "            print(\"------------- tratando de convertir en texto -------------\")\n",
        "            # try converting it to text \n",
        "            rec = r.recognize_google(audio_listened,language=\"es-ES\") \n",
        "            print(rec)\n",
        "            # write the output to the file. \n",
        "            fh.write(rec+\". \") \n",
        "        \n",
        "        # catch any errors. \n",
        "        except sr.UnknownValueError: \n",
        "            print(\"Could not understand audio\") \n",
        "\n",
        "        except sr.RequestError as e: \n",
        "            print(\"Could not request results. check your internet connection\")\n",
        "    \n",
        "    os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "SpeechToText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python36964bit369pyenv8867ba5dd5794cf898429060b96b97c8",
      "display_name": "Python 3.6.9 64-bit ('3.6.9': pyenv)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}